{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://pranav-pc:4040\n",
       "SparkContext available as 'sc' (version = 3.0.0-preview2, master = local[*], app id = local-1580763318127)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.DataFrame\n",
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.ml.Pipeline\n",
       "import org.apache.spark.ml.Model\n",
       "import org.apache.spark.ml.classification.LogisticRegression\n",
       "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
       "import org.apache.spark.ml.feature.Binarizer\n",
       "import org.apache.spark.ml.feature.{RegexTokenizer, NGram}\n",
       "import org.apache.spark.ml.feature.{HashingTF, IDF}\n",
       "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession;\n",
    "\n",
    "//import statistics.functions._;\n",
    "\n",
    "import org.apache.spark.sql.DataFrame;\n",
    "import org.apache.spark.sql.types._;\n",
    "import org.apache.spark.sql.functions._;\n",
    "import org.apache.spark.ml.Pipeline;\n",
    "import org.apache.spark.ml.Model;\n",
    "import org.apache.spark.ml.classification.LogisticRegression;\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator;\n",
    "import org.apache.spark.ml.feature.Binarizer;\n",
    "import org.apache.spark.ml.feature.{RegexTokenizer, NGram};\n",
    "import org.apache.spark.ml.feature.{HashingTF, IDF};\n",
    "import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path: String = hdfs://localhost:9000/TextMining/tokens/part-00000\n",
       "original_schema: org.apache.spark.sql.types.StructType = StructType(StructField(product,StringType,true), StructField(votes,IntegerType,true), StructField(rate,DoubleType,true), StructField(text,StringType,true))\n",
       "original_data: org.apache.spark.sql.DataFrame = [product: string, votes: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val path: String = \"hdfs://localhost:9000/TextMining/tokens/part-00000\";\n",
    "\n",
    "// \"rate\" must be Double because it can be easily binarized by Spark\n",
    "val original_schema = new StructType(Array(\n",
    "  StructField(\"product\", StringType,  true),\n",
    "  StructField(\"votes\",   IntegerType, true),\n",
    "  StructField(\"rate\",    DoubleType,  true),\n",
    "  StructField(\"text\",    StringType,  true)));\n",
    "\n",
    "val original_data:DataFrame = spark.read\n",
    "  .options(Map(\"delimiter\" -> \"\\t\"))\n",
    "  .schema(original_schema)\n",
    "  .csv(path)\n",
    "  .na.drop();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----+--------------------+\n",
      "|   product|votes|rate|                text|\n",
      "+----------+-----+----+--------------------+\n",
      "|B01CT5KLIY|    1| 4.0|love idea two wom...|\n",
      "|B01CT5KQMA|    1| 5.0|must veri well gr...|\n",
      "|B01CT5KQMA|    1| 5.0|charact likabl pl...|\n",
      "|B01CT6LRK4|    1| 4.0|abl final sit sur...|\n",
      "|B01CT6LRK4|    1| 2.0|few basic tip say...|\n",
      "+----------+-----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binarizer: org.apache.spark.ml.feature.Binarizer = Binarizer: uid=binarizer_1f2ecfd8bb5d\n",
       "tokenizer: org.apache.spark.ml.feature.RegexTokenizer = regexTok_4eca11e23721\n",
       "ngrams: org.apache.spark.ml.feature.NGram = NGram: uid=ngram_08dd240d9a73, n=2\n",
       "tf: org.apache.spark.ml.feature.HashingTF = HashingTF: uid=hashingTF_1ed4df629fa6, binary=false, numFeatures=262144\n",
       "idf: org.apache.spark.ml.feature.IDF = idf_6db681b5f222\n",
       "classifierMod: org.apache.spark.ml.classification.LogisticRegression = logreg_9cdc54499216\n",
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_0234d6e5c92e\n",
       "paramGrid: Array[org.apache.spark.ml.param.ParamMap] =\n",
       "Array({\n",
       "\tngram_08dd240d9a73-n: 1,\n",
       "\tlogreg_9cdc54499216-regParam: 0.01\n",
       "}, {\n",
       "\tngram_08dd240d9a73-n: 1,\n",
       "\tlogreg_9cdc54499216-regParam: 0.05\n",
       "}, {\n",
       "\tngram_08dd240d9a73-n: 1,\n",
       "\tl...\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val binarizer = new Binarizer()\n",
    "  .setInputCol(\"rate\")\n",
    "  .setOutputCol(\"label\")\n",
    "  .setThreshold(3.5);\n",
    "\n",
    "// get n-grams\n",
    "val tokenizer = new RegexTokenizer()\n",
    "  .setInputCol(\"text\")\n",
    "  .setOutputCol(\"tokens\")\n",
    "  .setPattern(\"\\\\W\");\n",
    "val ngrams = new NGram()\n",
    "  .setInputCol(tokenizer.getOutputCol)\n",
    "  .setOutputCol(\"n-grams\");\n",
    "\n",
    "// calc tf-idf \n",
    "val tf = new HashingTF()\n",
    "  .setInputCol(ngrams.getOutputCol)\n",
    "  .setOutputCol(\"tf\");\n",
    "val idf = new IDF()\n",
    "  .setInputCol(tf.getOutputCol)\n",
    "  .setOutputCol(\"tf-idf\")\n",
    "  .setMinDocFreq(3);\n",
    "\n",
    "// build the classifier\n",
    "val classifierMod = new LogisticRegression()\n",
    "  .setMaxIter(10)\n",
    "  .setFeaturesCol(idf.getOutputCol)\n",
    "  .setLabelCol(binarizer.getOutputCol);\n",
    "\n",
    "// this is the pipeline that data follows to be evaluated\n",
    "val pipeline = new Pipeline()\n",
    "  .setStages(Array(binarizer, tokenizer, ngrams, tf, idf, classifierMod));\n",
    "\n",
    "// a little of optimization: try different hyperparameters\n",
    "val paramGrid = new ParamGridBuilder()\n",
    "  .addGrid(classifierMod.regParam, Array(0.01, 0.05, 0.1))\n",
    "  .addGrid(ngrams.n, Array(1, 2, 3))\n",
    "  .build();\n",
    "\n",
    "// do it with a cross validation on the train set (3 folds)\n",
    "val cv = new CrossValidator()\n",
    "  .setEstimator(pipeline)\n",
    "  .setEvaluator(new BinaryClassificationEvaluator)\n",
    "  .setEstimatorParamMaps(paramGrid)\n",
    "  .setNumFolds(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... \n",
      "done!\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "\tngram_08dd240d9a73-n: 1,\n",
      "\tlogreg_9cdc54499216-regParam: 0.01\n",
      "}\n",
      "0.894217505803825\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "\tngram_08dd240d9a73-n: 1,\n",
      "\tlogreg_9cdc54499216-regParam: 0.05\n",
      "}\n",
      "0.9034031006521369\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "\tngram_08dd240d9a73-n: 1,\n",
      "\tlogreg_9cdc54499216-regParam: 0.1\n",
      "}\n",
      "0.905312185591742\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "\tngram_08dd240d9a73-n: 2,\n",
      "\tlogreg_9cdc54499216-regParam: 0.01\n",
      "}\n",
      "0.8443155195102902\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "\tngram_08dd240d9a73-n: 2,\n",
      "\tlogreg_9cdc54499216-regParam: 0.05\n",
      "}\n",
      "0.8644238243016412\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "\tngram_08dd240d9a73-n: 2,\n",
      "\tlogreg_9cdc54499216-regParam: 0.1\n",
      "}\n",
      "0.872029019745533\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "\tngram_08dd240d9a73-n: 3,\n",
      "\tlogreg_9cdc54499216-regParam: 0.01\n",
      "}\n",
      "0.6673848921888594\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "\tngram_08dd240d9a73-n: 3,\n",
      "\tlogreg_9cdc54499216-regParam: 0.05\n",
      "}\n",
      "0.6837430757007262\n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "\tngram_08dd240d9a73-n: 3,\n",
      "\tlogreg_9cdc54499216-regParam: 0.1\n",
      "}\n",
      "0.6908928013842282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.tuning.CrossValidatorModel = CrossValidatorModel: uid=cv_067743676650, bestModel=pipeline_0234d6e5c92e, numFolds=3\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"Training... \");\n",
    "val model = cv.fit(original_data);\n",
    "println(\"done!\");\n",
    "\n",
    "// print results\n",
    "for (i <- 0 until model.avgMetrics.size) {\n",
    "  println(\"\\n\\n\");\n",
    "  println(model.getEstimatorParamMaps(i));\n",
    "  println(model.avgMetrics(i));\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
